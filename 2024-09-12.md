# News for September 12, 2024

## Most Americans don't trust AI-powered election information: AP-NORC/USAFacts survey
[https://apnews.com/article/ai-chatbots-misinformation-voting-election-2024-7131822c0f2ebe843b4c7e3cb111a3d3](https://apnews.com/article/ai-chatbots-misinformation-voting-election-2024-7131822c0f2ebe843b4c7e3cb111a3d3)

A survey by The Associated Press and NORC/USAFacts found that most Americans do not trust artificial intelligence-powered chatbots or search results to provide accurate answers, especially when it comes to information about elections. Only a small portion of respondents believed AI-generated results were always or often based on factual information.

## AI safety showdown: Yann LeCun slams California’s SB 1047 as Geoffrey Hinton backs new regulations
[https://venturebeat.com/ai/ai-safety-showdown-yann-lecun-slams-californias-sb-1047-as-geoffrey-hinton-backs-new-regulations/](https://venturebeat.com/ai/ai-safety-showdown-yann-lecun-slams-californias-sb-1047-as-geoffrey-hinton-backs-new-regulations/)

The article discusses the disagreement between two artificial intelligence (AI) pioneers, Yann LeCun and Geoffrey Hinton, over California's SB 1047 bill, which aims to regulate AI development. LeCun criticized supporters of the bill, saying they have a distorted view of what is coming next with AI due to inexperience, naïveté, and wild overestimates of their employer's lead. Hinton, on the other hand, endorsed the bill, citing potential catastrophic harm from powerful AI models. The debate highlights the complexity of regulating a rapidly evolving technology and may set a precedent for how societies grapple with the promises and perils of increasingly powerful AI systems.

## Generative AI as a tool for truth - Science
[https://news.google.com/rss/articles/CBMiYEFVX3lxTFAzMzFCU3VWeTRpb0E5U3Q5Ym1Jc25kYzlWejFrVW1TeWgxNFYwbjJyenFRVzJFN2ZPV2EyVGljUkh4NXkwYWdiSUhQVC1MUDJ5czRBWENuN1VVQ0tFOUx2cw?oc=5](https://news.google.com/rss/articles/CBMiYEFVX3lxTFAzMzFCU3VWeTRpb0E5U3Q5Ym1Jc25kYzlWejFrVW1TeWgxNFYwbjJyenFRVzJFN2ZPV2EyVGljUkh4NXkwYWdiSUhQVC1MUDJ5czRBWENuN1VVQ0tFOUx2cw?oc=5)



## AI can change belief in conspiracy theories, study finds
[https://www.theguardian.com/science/2024/sep/12/ai-can-change-belief-in-conspiracy-theories-study-finds](https://www.theguardian.com/science/2024/sep/12/ai-can-change-belief-in-conspiracy-theories-study-finds)

Researchers found that the AI system was able to reduce people’s belief in a conspiracy theory by pointing out flaws and inconsistencies, and by acknowledging and validating their emotions.

## This Chatbot Pulls People Away From Conspiracy Theories
[https://www.nytimes.com/2024/09/12/health/chatbot-debunk-conspiracy-theories.html](https://www.nytimes.com/2024/09/12/health/chatbot-debunk-conspiracy-theories.html)

Here is a brief summary of the article, no longer than 200 words:

Meta, the parent company of Facebook and Instagram, is updating its labeling system for edited content on these platforms. The company will now hide the "AI Info" label in a menu for images and videos that have been lightly edited using generative AI tools. Previously, the label was displayed directly beneath the user's name. This change aims to better reflect the extent of AI used in editing content. Meta says it will still display the "AI info" label for content generated by an AI tool, but will now check for industry-shared signals, such as digital watermarks applied by other companies like Adobe and Google. The updated labeling system is intended to provide more transparency about edited content, while also avoiding false positives on real images that have been manipulated using generative AI tools.

## Learning to Reason with LLMs
[https://openai.com/index/learning-to-reason-with-llms](https://openai.com/index/learning-to-reason-with-llms)

Here is a brief summary of the article in 200 words or less:

Meta, the parent company of Facebook and Instagram, is changing how it labels edited content on its platforms. Previously, AI-generated content was labeled as "Made with AI" directly beneath the user's name. However, Meta is now moving to a more nuanced approach where labels for AI-edited content will appear behind a menu, rather than front and center. This change aims to "better reflect the extent of AI used" across images and videos on the platforms. The company says this update will start rolling out next week. Meanwhile, labels for AI-generated content remain prominent, as do those for content that has been self-disclosed or flagged by industry-shared signals.

## How to prompt on GPT-o1
[https://venturebeat.com/ai/how-to-prompt-on-gpt-o1/](https://venturebeat.com/ai/how-to-prompt-on-gpt-o1/)

The article discusses how to prompt on GPT-o1, a new model from OpenAI that promises to be more powerful and better at reasoning than previous models. Unlike previous models, GPT-o1 does not require as much guidance and performs best with straightforward prompts. The article provides tips for using GPT-o1, including keeping prompts simple and direct, avoiding chain-of-thought prompts, and limiting additional context.

## Facebook and Instagram are making AI labels less prominent on edited content
[https://www.theverge.com/2024/9/12/24242998/facebook-instagram-ai-label-update-edited-content](https://www.theverge.com/2024/9/12/24242998/facebook-instagram-ai-label-update-edited-content)

Here is a brief summary of the article in 200 words:

Meta, the parent company of Facebook and Instagram, is updating its labeling policy for edited content that uses generative AI. Previously, any image or video that had been edited with an AI tool would display a prominent "AI Info" label. However, this labeling was criticized for incorrectly tagging real photos taken by humans.

To address these concerns, Meta is introducing a new system where the "AI Info" label will be hidden behind a menu on edited content that has only been lightly adjusted using AI tools. The label will still appear directly beneath user names for fully AI-generated content or images that have been heavily manipulated with AI.

The changes aim to provide more nuance in labeling edited content and avoid mistakenly attributing AI-generated photos as real. Meta is starting the rollout of these updates next week, although details on specific systems being used to detect AI-generated content are still unclear.

## Forget GPT-5! OpenAI launches new AI model family o1 claiming PhD-level performance
[https://venturebeat.com/ai/forget-gpt-5-openai-launches-new-ai-model-family-o1-claiming-phd-level-performance/](https://venturebeat.com/ai/forget-gpt-5-openai-launches-new-ai-model-family-o1-claiming-phd-level-performance/)

This article discusses the latest advancements in OpenAI's AI models, specifically the o1-preview and o1-mini models. Here are some key points:

**o1-Preview Model:**

* This model excels in complex problem-solving, performing at a level close to that of PhD students in areas like physics, chemistry, and biology.
* It ranks in the 89th percentile in Codeforces competitions, showcasing its ability to handle multi-step workflows, debug complex code, and generate accurate solutions.
* The model demonstrated its prowess by solving 83% of problems on the International Mathematics Olympiad (IMO) qualifying exam.

**o1-Mini Model:**

* This is a more streamlined version designed to offer faster and cheaper reasoning capabilities, optimized primarily for coding and STEM tasks.
* It scored 70% on the IMO math benchmark, nearly matching the 74% of o1-preview while offering a significantly lower inference cost.
* The model performed competitively in coding evaluations, achieving an Elo score of 1650 on Codeforces, positioning it among the top 86% of programmers.

**Key Features and Availability:**

* Both models are available for use in ChatGPT by Plus and Team users, with Enterprise and Edu users gaining access next week.
* The models are also available via the OpenAI API for developers who qualify for API usage tier 5, though initial rate limits will apply.

**Safety and Security Enhancements:**

* Both models incorporate a new safety training approach that enhances their ability to follow safety and alignment guidelines.
* o1-preview scored an impressive 84 on one of its toughest jailbreaking tests, a significant improvement over GPT-4o's score of 22.
* OpenAI has entered into agreements with the U.S. and U.K. AI Safety Institutes to evaluate and test future AI systems.

**Future Plans:**

* OpenAI plans to regularly update and improve these models, including adding features like browsing, file and image uploading, and function calling.
* The company will continue to develop both its GPT and o1 series, further expanding the capabilities of AI in various fields.

## DataGemma: Using real-world data to address AI hallucinations
[https://blog.google/technology/ai/google-datagemma-ai-llm/](https://blog.google/technology/ai/google-datagemma-ai-llm/)

Here is the rewritten text in a more formal and neutral tone:

Google has released notebooks for both the RIG and RAG approaches to learn about how Data Commons and Gemma work together. The notebooks are available on Colab.

To understand more about this collaboration, readers can refer to a research post on Google's blog.

This announcement is related to AI technology and was posted in the AI section of Google's blog.

Other stories related to AI include:

* Google.org's new initiatives to help small businesses grow with AI tools.
* NotebookLM's audio overview feature that allows users to listen to conversations about their sources.
* Three new AI tools for nonprofits from Google.org.
* Accelerating Google.org's future impact with AI.
* Upgrading Video Action Campaigns to Demand Gen in Google Ads.

The post includes links to these related stories and provides a way to subscribe to Google's newsletter.

