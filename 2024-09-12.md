# News for September 12 2024

## AI can change belief in conspiracy theories, study finds
[https://www.theguardian.com/science/2024/sep/12/ai-can-change-belief-in-conspiracy-theories-study-finds](https://www.theguardian.com/science/2024/sep/12/ai-can-change-belief-in-conspiracy-theories-study-finds)

null

## This Chatbot Pulls People Away From Conspiracy Theories
[https://www.nytimes.com/2024/09/12/health/chatbot-debunk-conspiracy-theories.html](https://www.nytimes.com/2024/09/12/health/chatbot-debunk-conspiracy-theories.html)

Here is a brief summary of the article, no longer than 200 words:

Meta, the parent company of Facebook and Instagram, is updating its labeling system for edited content on these platforms. The company will now hide the "AI Info" label in a menu for images and videos that have been lightly edited using generative AI tools. Previously, the label was displayed directly beneath the user's name. This change aims to better reflect the extent of AI used in editing content. Meta says it will still display the "AI info" label for content generated by an AI tool, but will now check for industry-shared signals, such as digital watermarks applied by other companies like Adobe and Google. The updated labeling system is intended to provide more transparency about edited content, while also avoiding false positives on real images that have been manipulated using generative AI tools.

## Learning to Reason with LLMs
[https://openai.com/index/learning-to-reason-with-llms](https://openai.com/index/learning-to-reason-with-llms)

Here is a brief summary of the article in 200 words or less:

Meta, the parent company of Facebook and Instagram, is changing how it labels edited content on its platforms. Previously, AI-generated content was labeled as "Made with AI" directly beneath the user's name. However, Meta is now moving to a more nuanced approach where labels for AI-edited content will appear behind a menu, rather than front and center. This change aims to "better reflect the extent of AI used" across images and videos on the platforms. The company says this update will start rolling out next week. Meanwhile, labels for AI-generated content remain prominent, as do those for content that has been self-disclosed or flagged by industry-shared signals.

## Facebook and Instagram are making AI labels less prominent on edited content
[https://www.theverge.com/2024/9/12/24242998/facebook-instagram-ai-label-update-edited-content](https://www.theverge.com/2024/9/12/24242998/facebook-instagram-ai-label-update-edited-content)

Here is a brief summary of the article, no longer than 200 words:

Meta, the company behind Facebook and Instagram, is updating its labeling system for content that has been edited or manipulated using generative AI. Previously, the "AI Info" tag was displayed directly beneath the user's name on images and videos edited with AI tools. However, Meta will now display this label within a menu in the top-right corner of edited content, rather than prominently on the post itself. This change aims to "better reflect the extent of AI used" across images and videos on the platforms. The update also means that users may not be immediately aware if an image or video has been heavily manipulated with AI, potentially leading to misleading information being shared online.

## Forget GPT-5! OpenAI launches new AI model family o1 claiming PhD-level performance
[https://venturebeat.com/ai/forget-gpt-5-openai-launches-new-ai-model-family-o1-claiming-phd-level-performance/](https://venturebeat.com/ai/forget-gpt-5-openai-launches-new-ai-model-family-o1-claiming-phd-level-performance/)

This article discusses the launch of two new AI models, o1-preview and o1-mini, by OpenAI. Here's a summary:

**Key Points:**

*   The o1-preview model has demonstrated impressive performance in various fields, including physics, chemistry, biology, and coding, ranking close to PhD students.
*   In benchmark tasks like the International Mathematics Olympiad (IMO) qualifying exam, o1-preview solved 83% of problems, a significant improvement over its predecessor GPT-4o's 13%.
*   The o1-mini model is less powerful but cheaper, scoring 70% in the IMO math benchmark and achieving an Elo score of 1650 on Codeforces.
*   Both models have enhanced safety features, including improved ability to follow safety guidelines, and are available via the OpenAI API for developers who qualify for tier 5 usage.

**Safety and Security Enhancements:**

*   The o1-preview model scored a significant improvement over GPT-4o in jailbreaking tests.
*   OpenAI has partnered with AI Safety Institutes to evaluate future AI systems.
*   Regular testing, red-teaming, and board-level oversight ensure the company's commitment to safety.

**Future Developments:**

*   The o1 series will be regularly updated and improved, including features like browsing, file uploading, and function calling.
*   OpenAI plans to continue developing both GPT and o1 series for various applications.

Overall, the launch of o1-preview and o1-mini models represents a significant step forward in AI capabilities, with enhanced safety features and improved performance.

## DataGemma: Using real-world data to address AI hallucinations
[https://blog.google/technology/ai/google-datagemma-ai-llm/](https://blog.google/technology/ai/google-datagemma-ai-llm/)

Based on the text, here are some notes about the Data Commons and Gemma project:

**Data Commons and Gemma**: The project aims to ground AI in reality by providing a framework for connecting AI models with real-world data and knowledge. This is achieved through two approaches: RIG (Relational Information Grounding) and RAG (Relational Aggregation).

**RIG**: A method for grounding AI models in real-world data, which involves creating notebooks that demonstrate how to use Data Commons and Gemma together.

**RAG**: Another approach for connecting AI models with real-world knowledge, which also has a notebook available.

**Research Post**: The blog post provides more information about the project, highlighting its potential to improve the accuracy and reliability of AI models.

Some possible discussion points or questions based on this text could be:

* What are the benefits of using Data Commons and Gemma together?
* How does RIG differ from RAG in terms of connecting AI models with real-world data and knowledge?
* What kind of real-world applications can benefit from the use of Data Commons and Gemma?
* How can researchers and developers learn more about this project and its potential uses?

## AI can change belief in conspiracy theories, study finds
[https://www.theguardian.com/science/2024/sep/12/ai-can-change-belief-in-conspiracy-theories-study-finds](https://www.theguardian.com/science/2024/sep/12/ai-can-change-belief-in-conspiracy-theories-study-finds)

null

## This Chatbot Pulls People Away From Conspiracy Theories
[https://www.nytimes.com/2024/09/12/health/chatbot-debunk-conspiracy-theories.html](https://www.nytimes.com/2024/09/12/health/chatbot-debunk-conspiracy-theories.html)

Here is a brief summary of the article, no longer than 200 words:

Meta, the parent company of Facebook and Instagram, is updating its labeling system for edited content on these platforms. The company will now hide the "AI Info" label in a menu for images and videos that have been lightly edited using generative AI tools. Previously, the label was displayed directly beneath the user's name. This change aims to better reflect the extent of AI used in editing content. Meta says it will still display the "AI info" label for content generated by an AI tool, but will now check for industry-shared signals, such as digital watermarks applied by other companies like Adobe and Google. The updated labeling system is intended to provide more transparency about edited content, while also avoiding false positives on real images that have been manipulated using generative AI tools.

## Learning to Reason with LLMs
[https://openai.com/index/learning-to-reason-with-llms](https://openai.com/index/learning-to-reason-with-llms)

Here is a brief summary of the article in 200 words or less:

Meta, the parent company of Facebook and Instagram, is changing how it labels edited content on its platforms. Previously, AI-generated content was labeled as "Made with AI" directly beneath the user's name. However, Meta is now moving to a more nuanced approach where labels for AI-edited content will appear behind a menu, rather than front and center. This change aims to "better reflect the extent of AI used" across images and videos on the platforms. The company says this update will start rolling out next week. Meanwhile, labels for AI-generated content remain prominent, as do those for content that has been self-disclosed or flagged by industry-shared signals.

## Facebook and Instagram are making AI labels less prominent on edited content
[https://www.theverge.com/2024/9/12/24242998/facebook-instagram-ai-label-update-edited-content](https://www.theverge.com/2024/9/12/24242998/facebook-instagram-ai-label-update-edited-content)

Here is a brief summary of the article, no longer than 200 words:

Meta, the company behind Facebook and Instagram, is updating its labeling system for content that has been edited or manipulated using generative AI. Previously, the "AI Info" tag was displayed directly beneath the user's name on images and videos edited with AI tools. However, Meta will now display this label within a menu in the top-right corner of edited content, rather than prominently on the post itself. This change aims to "better reflect the extent of AI used" across images and videos on the platforms. The update also means that users may not be immediately aware if an image or video has been heavily manipulated with AI, potentially leading to misleading information being shared online.

## Forget GPT-5! OpenAI launches new AI model family o1 claiming PhD-level performance
[https://venturebeat.com/ai/forget-gpt-5-openai-launches-new-ai-model-family-o1-claiming-phd-level-performance/](https://venturebeat.com/ai/forget-gpt-5-openai-launches-new-ai-model-family-o1-claiming-phd-level-performance/)

This article discusses the launch of two new AI models, o1-preview and o1-mini, by OpenAI. Here's a summary:

**Key Points:**

*   The o1-preview model has demonstrated impressive performance in various fields, including physics, chemistry, biology, and coding, ranking close to PhD students.
*   In benchmark tasks like the International Mathematics Olympiad (IMO) qualifying exam, o1-preview solved 83% of problems, a significant improvement over its predecessor GPT-4o's 13%.
*   The o1-mini model is less powerful but cheaper, scoring 70% in the IMO math benchmark and achieving an Elo score of 1650 on Codeforces.
*   Both models have enhanced safety features, including improved ability to follow safety guidelines, and are available via the OpenAI API for developers who qualify for tier 5 usage.

**Safety and Security Enhancements:**

*   The o1-preview model scored a significant improvement over GPT-4o in jailbreaking tests.
*   OpenAI has partnered with AI Safety Institutes to evaluate future AI systems.
*   Regular testing, red-teaming, and board-level oversight ensure the company's commitment to safety.

**Future Developments:**

*   The o1 series will be regularly updated and improved, including features like browsing, file uploading, and function calling.
*   OpenAI plans to continue developing both GPT and o1 series for various applications.

Overall, the launch of o1-preview and o1-mini models represents a significant step forward in AI capabilities, with enhanced safety features and improved performance.

## DataGemma: Using real-world data to address AI hallucinations
[https://blog.google/technology/ai/google-datagemma-ai-llm/](https://blog.google/technology/ai/google-datagemma-ai-llm/)

Based on the text, here are some notes about the Data Commons and Gemma project:

**Data Commons and Gemma**: The project aims to ground AI in reality by providing a framework for connecting AI models with real-world data and knowledge. This is achieved through two approaches: RIG (Relational Information Grounding) and RAG (Relational Aggregation).

**RIG**: A method for grounding AI models in real-world data, which involves creating notebooks that demonstrate how to use Data Commons and Gemma together.

**RAG**: Another approach for connecting AI models with real-world knowledge, which also has a notebook available.

**Research Post**: The blog post provides more information about the project, highlighting its potential to improve the accuracy and reliability of AI models.

Some possible discussion points or questions based on this text could be:

* What are the benefits of using Data Commons and Gemma together?
* How does RIG differ from RAG in terms of connecting AI models with real-world data and knowledge?
* What kind of real-world applications can benefit from the use of Data Commons and Gemma?
* How can researchers and developers learn more about this project and its potential uses?

